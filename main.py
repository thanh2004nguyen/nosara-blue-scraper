from playwright.sync_api import sync_playwright
import time
from datetime import datetime, timezone, timedelta
import json
import re
import traceback

CLASS_ITEMS_XPATH = "//div[@role='list']//div[@role='listitem']"

def get_cst_date():
    cst = timezone(timedelta(hours=-6))
    return datetime.now(cst).date()

def get_next_day(current_date):
    return current_date + timedelta(days=1)

def parse_time_to_24h(time_str):
    try:
        time_str = time_str.strip().lower()
        pattern = r'(\d{1,2}):(\d{2})\s*(am|pm)'
        match = re.match(pattern, time_str)
        if match:
            hour = int(match.group(1))
            minute = int(match.group(2))
            period = match.group(3)
            if period == 'pm' and hour != 12:
                hour += 12
            elif period == 'am' and hour == 12:
                hour = 0
            return f"{hour:02d}:{minute:02d}"
        else:
            return time_str
    except Exception:
        return time_str

def calculate_end_time(start_time, duration):
    try:
        start_hour, start_minute = map(int, start_time.split(':'))
        duration_str = duration.lower()
        hours = 0
        minutes = 0
        hour_pattern = r'(\d+)\s*hr'
        minute_pattern = r'(\d+)\s*min'
        hour_match = re.search(hour_pattern, duration_str)
        minute_match = re.search(minute_pattern, duration_str)
        if hour_match:
            hours = int(hour_match.group(1))
        if minute_match:
            minutes = int(minute_match.group(1))
        end_minute = start_minute + minutes
        end_hour = start_hour + hours + (end_minute // 60)
        end_minute = end_minute % 60
        return f"{end_hour:02d}:{end_minute:02d}"
    except Exception:
        return start_time

def get_week_range_from_html(html):
    """
    T√¨m chu·ªói d·∫°ng 'Dec 11 - Dec 17' trong HTML (n·∫øu c√≥) ƒë·ªÉ bi·∫øt week header.
    Tr·∫£ v·ªÅ string ho·∫∑c empty.
    """
    try:
        # match "Dec 11 - Dec 17" or "December 11 - December 17"
        m = re.search(r'([A-Za-z]{3,9}\s+\d{1,2}\s*-\s*[A-Za-z]{3,9}\s+\d{1,2})', html)
        if m:
            return m.group(1).strip()
    except:
        pass
    return ""

def click_next_week_button(page, wait_timeout=6000):
    """
    T√¨m ph·∫ßn t·ª≠ Next Week (nhi·ªÅu kh·∫£ nƒÉng l√† button/a/span c√≥ text '‚Ä∫', '>', 'Next', '¬ª', ...)
    Click n√≥ v√† ch·ªù week-range thay ƒë·ªïi. Tr·∫£ v·ªÅ True n·∫øu tu·∫ßn th·ª±c s·ª± thay ƒë·ªïi.
    """
    try:
        prev_html = page.content()
        prev_range = get_week_range_from_html(prev_html)

        # t√¨m candidate elements (button, a, span) c√≥ text ho·∫∑c attribute li√™n quan t·ªõi 'next'
        candidates = []
        # 1) c√°c button, a, span c√≥ aria-label/title ch·ª©a 'next' (case-insensitive)
        candidates.extend(page.query_selector_all("button[aria-label], a[aria-label], button[title], a[title], button, a, span"))
        # iterate v√† ch·ªçn element ph√π h·ª£p
        elem_to_click = None
        for el in candidates:
            try:
                text = (el.inner_text() or "").strip()
                aria = (el.get_attribute("aria-label") or "").strip()
                title = (el.get_attribute("title") or "").strip()
                # c√°c k√Ω t·ª± arrow ho·∫∑c t·ª´ 'next'
                if text in ("‚Ä∫", ">", "¬ª", "‚Üí") or re.search(r'\bnext\b', text, re.I) or re.search(r'\bnext\b', aria, re.I) or re.search(r'\bnext\b', title, re.I):
                    # ensure visible and enabled
                    try:
                        if not el.is_visible():
                            continue
                    except:
                        pass
                    disabled = el.get_attribute("disabled") == "true" or el.get_attribute("aria-disabled") == "true"
                    if disabled:
                        continue
                    elem_to_click = el
                    break
            except Exception:
                continue

        if not elem_to_click:
            # fallback: t√¨m lu√¥n ph·∫ßn t·ª≠ c√≥ ch√≠nh x√°c d·∫•u '‚Ä∫' b·∫±ng xpath
            xpath_candidates = page.locator("xpath=//button[normalize-space(.)='‚Ä∫'] | //a[normalize-space(.)='‚Ä∫'] | //span[normalize-space(.)='‚Ä∫']")
            if xpath_candidates.count() > 0:
                el = xpath_candidates.first
                try:
                    if el.is_visible():
                        elem_to_click = el
                except:
                    elem_to_click = el

        if not elem_to_click:
            return False

        # click v√† ch·ªù week-range thay ƒë·ªïi
        try:
            elem_to_click.click()
        except Exception:
            # th·ª≠ b·∫±ng evaluate n·∫øu click() fail
            try:
                page.evaluate("(el) => el.click()", elem_to_click)
            except:
                pass

        # ch·ªù thay ƒë·ªïi week-range (d·ª±a tr√™n HTML content)
        deadline = time.time() + (wait_timeout/1000)
        while time.time() < deadline:
            html = page.content()
            new_range = get_week_range_from_html(html)
            if new_range and new_range != prev_range:
                # success
                time.sleep(0.6)  # th√™m 1 ch√∫t ·ªïn ƒë·ªãnh
                return True
            time.sleep(0.3)
        # n·∫øu kh√¥ng thay ƒë·ªïi, v·∫´n c√≥ th·ªÉ ƒë√£ thay DOM m√† week-range kh√¥ng ph√π h·ª£p - ch·ªù m·ªôt ch√∫t r·ªìi tr·∫£ False
        time.sleep(0.5)
        return False

    except Exception as e:
        print("‚ö†Ô∏è click_next_week_button l·ªói:", e)
        traceback.print_exc()
        return False

def find_and_click_date(page, target_date, max_next_clicks=8):
    """
    T√¨m n√∫t ch·ª©a ng√†y (s·ªë ng√†y) visible v√† click.
    N·∫øu kh√¥ng th·∫•y trong tu·∫ßn hi·ªán t·∫°i s·∫Ω click next week r·ªìi th·ª≠ l·∫°i (max_next_clicks l·∫ßn).
    """
    day_text = str(target_date.day)
    attempts = 0
    while attempts <= max_next_clicks:
        # t√¨m t·∫•t c·∫£ n√∫t c√≥ ch·ª©a text day_text
        # (d√πng locator button elements)
        btns = page.locator(f"button:has-text('{day_text}'), a:has-text('{day_text}'), span:has-text('{day_text}')")
        count = btns.count()
        if count > 0:
            # t√¨m n√∫t visible v√† kh√¥ng b·ªã disabled
            for i in range(count):
                try:
                    el = btns.nth(i)
                    # visible?
                    try:
                        if not el.is_visible():
                            continue
                    except:
                        pass
                    # kh√¥ng disabled
                    if el.get_attribute("aria-disabled") == "true" or el.get_attribute("disabled") == "true":
                        continue
                    # click
                    try:
                        el.click()
                    except Exception:
                        page.evaluate("(e) => e.click()", el)
                    # ch·ªù m·ªôt ch√∫t cho n·ªôi dung c·∫≠p nh·∫≠t
                    time.sleep(0.8)
                    return True
                except Exception:
                    continue
        # n·∫øu ch∆∞a th·∫•y -> click next week v√† th·ª≠ l·∫°i
        attempts += 1
        print(f"üîÅ Kh√¥ng th·∫•y ng√†y {day_text} (attempt {attempts}/{max_next_clicks}) ‚Äî th·ª≠ Next Week")
        if not click_next_week_button(page):
            print("‚úó Kh√¥ng th·ªÉ click Next Week (ho·∫∑c tu·∫ßn kh√¥ng ƒë·ªïi).")
            return False
        time.sleep(0.6)
    print(f"‚úó ƒê√£ th·ª≠ {max_next_clicks} l·∫ßn next-week m√† v·∫´n kh√¥ng t√¨m th·∫•y ng√†y {day_text}")
    return False

def wait_for_content_change(page, previous_count, timeout_ms=9000):
    try:
        end = time.time() + (timeout_ms / 1000)
        while time.time() < end:
            try:
                if page.locator('text="No Classes Available"').count() > 0:
                    return True
            except:
                pass
            try:
                new_count = page.locator(CLASS_ITEMS_XPATH).count()
                if new_count != previous_count:
                    return True
            except:
                pass
            page.wait_for_timeout(250)
        return False
    except Exception as e:
        print("‚ö†Ô∏è wait_for_content_change l·ªói:", e)
        return False

def extract_class_info(page, current_date):
    try:
        try:
            if page.locator('text="No Classes Available"').count() > 0:
                return "NO_CLASSES"
        except:
            pass

        class_items = page.locator(CLASS_ITEMS_XPATH)
        total_classes = class_items.count()
        classes_info = []
        for i in range(total_classes):
            try:
                rich_text_xpath = f"({CLASS_ITEMS_XPATH})[{i+1}]//div[@data-testid='richTextElement']"
                rich_text_elements = page.locator(rich_text_xpath)
                if rich_text_elements.count() >= 4:
                    get_text = lambda idx: (rich_text_elements.nth(idx).inner_text().strip() if rich_text_elements.count() > idx else "").strip()
                    time_text = get_text(0)
                    duration_text = get_text(1)
                    class_name = get_text(2)
                    teacher_name = get_text(3)
                    spots_text = get_text(4) if rich_text_elements.count() > 4 else ""
                    start_time_24h = parse_time_to_24h(time_text)
                    end_time_24h = calculate_end_time(start_time_24h, duration_text)
                    class_info = {
                        "event_date": current_date.strftime('%Y-%m-%d'),
                        "start_time": start_time_24h,
                        "end_time": end_time_24h,
                        "title": class_name,
                        "instructor": teacher_name,
                        "location": "Nosara Blue",
                        "source_url": "https://www.nosarablue.com/classes",
                        "description": f"{class_name} - {duration_text} - {spots_text}".strip(" -"),
                        "category": "",
                        "tags": ""
                    }
                    classes_info.append(class_info)
            except Exception:
                continue
        return classes_info
    except Exception as e:
        print("‚ö†Ô∏è extract_class_info l·ªói:", e)
        traceback.print_exc()
        return []

def save_classes_to_file(classes_info, filename="classes_data.json"):
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(classes_info, f, ensure_ascii=False, indent=2)
        print(f"‚úì ƒê√£ l∆∞u {len(classes_info)} l·ªõp h·ªçc v√†o file: {filename}")
    except Exception as e:
        print(f"‚úó L·ªói khi l∆∞u file: {e}")

def main():
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=False)
        context = browser.new_context()
        page = context.new_page()
        url = "https://www.nosarablue.com/classes"
        print(f"üåê Truy c·∫≠p: {url}")
        try:
            page.goto(url, timeout=60000)
            page.wait_for_load_state('networkidle')
            print("‚úì Trang ƒë√£ load")
            current_date = get_cst_date()
            end_date = current_date + timedelta(days=30)
            all_classes_info = []
            while current_date <= end_date:
                print(f"\nüîé X·ª≠ l√Ω ng√†y: {current_date}")
                try:
                    prev_count = page.locator(CLASS_ITEMS_XPATH).count()
                except:
                    prev_count = -1
                found = find_and_click_date(page, current_date, max_next_clicks=8)
                if not found:
                    print(f"‚ö†Ô∏è B·ªè qua ng√†y {current_date} (kh√¥ng t√¨m th·∫•y tr√™n calendar).")
                    current_date = get_next_day(current_date)
                    continue
                changed = wait_for_content_change(page, prev_count, timeout_ms=9000)
                if not changed:
                    print("‚ö†Ô∏è N·ªôi dung c√≥ th·ªÉ ch∆∞a c·∫≠p nh·∫≠t, v·∫´n th·ª≠ extract.")
                classes_info = extract_class_info(page, current_date)
                if classes_info == "NO_CLASSES":
                    print(f"‚ú≥Ô∏è Ng√†y {current_date}: Kh√¥ng c√≥ l·ªõp.")
                elif isinstance(classes_info, list) and classes_info:
                    print(f"‚úì Ng√†y {current_date}: t√¨m th·∫•y {len(classes_info)} l·ªõp.")
                    all_classes_info.extend(classes_info)
                else:
                    print(f"‚ÑπÔ∏è Ng√†y {current_date}: kh√¥ng l·∫•y ƒë∆∞·ª£c l·ªõp (r·ªóng).")
                current_date = get_next_day(current_date)
                time.sleep(0.3)
            if all_classes_info:
                save_classes_to_file(all_classes_info)
            else:
                print("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu thu th·∫≠p ƒë∆∞·ª£c.")
            time.sleep(2)
        except Exception as e:
            print("‚úó L·ªói ch·∫°y:", e)
            traceback.print_exc()
        finally:
            browser.close()
            print("üîö ƒê√≥ng browser.")

if __name__ == "__main__":
    main()
