from playwright.sync_api import sync_playwright
import time
from datetime import datetime, timezone, timedelta
import json
import re
import traceback
from fastapi import FastAPI, HTTPException
from fastapi.responses import JSONResponse
import threading
import os

app = FastAPI()

# Global variable to store scraping status
scraping_status = {
    "is_running": False,
    "last_run": None,
    "total_classes": 0,
    "error": None,
    "progress": 0,
    "current_date": None,
    "daily_summary": []
}

def run_scraper():
    """H√†m ch·∫°y scraper trong thread ri√™ng - s·ª≠ d·ª•ng logic m·ªõi t·ª´ test_scraper.py"""
    global scraping_status
    
    scraping_status["is_running"] = True
    scraping_status["error"] = None
    scraping_status["progress"] = 0
    scraping_status["current_date"] = None
    scraping_status["daily_summary"] = []
    
    try:
        with sync_playwright() as p:
            # C·∫•u h√¨nh browser cho Render Linux environment
            browser = p.chromium.launch(
                headless=True,
                args=[
                    '--no-sandbox',
                    '--disable-setuid-sandbox',
                    '--disable-dev-shm-usage',
                    '--disable-accelerated-2d-canvas',
                    '--no-first-run',
                    '--no-zygote',
                    '--disable-gpu',
                    '--single-process',
                    '--disable-extensions',
                    '--disable-plugins',
                    '--disable-images'
                ]
            )
            page = browser.new_page()
            
            page.goto("https://www.nosarablue.com/classes")
            print("‚úÖ ƒê√£ truy c·∫≠p trang web th√†nh c√¥ng")
            
            time.sleep(10)  # Ch·ªù render
            print("‚è≥ ƒê√£ ch·ªù 10 gi√¢y")
            
            classes_data = []
            week_count = 0
            total_processed_days = 0
            max_days = 30
            daily_summary = []  # L∆∞u t·ªïng k·∫øt theo ng√†y
            
            while True:
                week_count += 1
                print(f"\n{'='*60}")
                print(f"üìÖ TU·∫¶N {week_count}")
                print(f"{'='*60}")
                
                # T√¨m ng√†y ƒëang ƒë∆∞·ª£c focus
                calendar_divs = page.locator('div[role="list"]')
                if calendar_divs.count() == 0:
                    print("‚ùå Kh√¥ng t√¨m th·∫•y calendar")
                    break
                
                # L·∫•y t·∫•t c·∫£ buttons trong calendar
                buttons = calendar_divs.first.locator('button')
                total_days = buttons.count()
                print(f"üìÖ T√¨m th·∫•y {total_days} ng√†y trong calendar")
                
                # T√¨m button ƒëang ƒë∆∞·ª£c disabled
                disabled_button_index = None
                for i in range(total_days):
                    button = buttons.nth(i)
                    if button.get_attribute("disabled") is not None:
                        disabled_button_index = i
                        current_date = button.get_attribute("aria-label")
                        print(f"üéØ T√¨m th·∫•y button disabled: {current_date} (index {i})")
                        break
                
                if disabled_button_index is None:
                    print("‚ùå Kh√¥ng t√¨m th·∫•y button disabled")
                    break
                
                # L·∫∑p t·ª´ button disabled tr·ªü ƒëi
                for day_index in range(disabled_button_index, total_days):
                    # Ki·ªÉm tra ƒëi·ªÅu ki·ªán d·ª´ng
                    if total_processed_days >= max_days:
                        print(f"\nüéØ ƒê√£ ƒë·∫°t gi·ªõi h·∫°n {max_days} ng√†y, d·ª´ng scraper")
                        break
                    
                    total_processed_days += 1
                    scraping_status["progress"] = int((total_processed_days / max_days) * 100)
                    print(f"\n{'='*50}")
                    print(f"üìÖ ƒêang x·ª≠ l√Ω ng√†y {total_processed_days}/{max_days}")
                    
                    # L·∫•y ng√†y hi·ªán t·∫°i ƒëang ƒë∆∞·ª£c focus
                    buttons = calendar_divs.first.locator('button')
                    current_date = None
                    for i in range(buttons.count()):
                        button = buttons.nth(i)
                        if button.get_attribute("disabled") is not None:
                            current_date = button.get_attribute("aria-label")
                            scraping_status["current_date"] = current_date
                            print(f"üéØ Ng√†y hi·ªán t·∫°i: {current_date}")
                            break
                    
                    # L·∫•y d·ªØ li·ªáu l·ªõp h·ªçc cho ng√†y hi·ªán t·∫°i
                    if calendar_divs.count() >= 2:
                        classes_div = calendar_divs.nth(1)
                        list_items = classes_div.locator('div[role="listitem"]')
                        day_classes_count = list_items.count()
                        
                        print(f"üìä T√¨m th·∫•y {day_classes_count} l·ªõp h·ªçc cho ng√†y {current_date}")
                        
                        if day_classes_count > 0:
                            for i in range(day_classes_count):
                                item = list_items.nth(i)
                                all_texts = item.locator('*').all_text_contents()
                                unique_texts = list(dict.fromkeys([text.strip() for text in all_texts if text.strip()]))
                                
                                # C·∫£i thi·ªán logic x·ª≠ l√Ω th√¥ng tin
                                # T√¨m th·ªùi gian (ch·ª©a am/pm v√† c√≥ d·∫°ng gi·ªù:ph√∫t)
                                time_info = None
                                for text in unique_texts:
                                    if ('am' in text.lower() or 'pm' in text.lower()) and ':' in text and len(text) < 10:
                                        time_info = text
                                        break
                                
                                # T√¨m th·ªùi l∆∞·ª£ng (ch·ª©a hr v√† min)
                                duration_info = None
                                for text in unique_texts:
                                    if ('hr' in text.lower() or 'min' in text.lower()) and len(text) < 15:
                                        duration_info = text
                                        break
                                
                                # T√¨m t√™n l·ªõp (lo·∫°i tr·ª´ c√°c t·ª´ kh√≥a kh√°c)
                                class_name_info = None
                                for text in unique_texts:
                                    if (text != time_info and text != duration_info and 
                                        'spots' not in text.lower() and 'book' not in text.lower() and
                                        'am' not in text.lower() and 'pm' not in text.lower() and
                                        len(text) > 5 and len(text) < 50):
                                        # Ki·ªÉm tra xem c√≥ ph·∫£i t√™n ng∆∞·ªùi kh√¥ng (qu√° ng·∫Øn ho·∫∑c qu√° d√†i)
                                        if not (len(text) < 3 or len(text) > 30):
                                            class_name_info = text
                                            break
                                
                                # T√¨m t√™n gi√°o vi√™n (th∆∞·ªùng l√† t√™n ng∆∞·ªùi, kh√¥ng ch·ª©a t·ª´ ƒë·∫∑c bi·ªát)
                                instructor_info = None
                                for text in unique_texts:
                                    if (text != time_info and text != duration_info and text != class_name_info and
                                        'spots' not in text.lower() and 'book' not in text.lower() and
                                        'am' not in text.lower() and 'pm' not in text.lower() and
                                        'hr' not in text.lower() and 'min' not in text.lower() and
                                        len(text) > 2 and len(text) < 30):
                                        # Ki·ªÉm tra xem c√≥ ph·∫£i t√™n ng∆∞·ªùi kh√¥ng
                                        if not any(char.isdigit() for char in text):
                                            instructor_info = text
                                            break
                                
                                # T√¨m description (spots)
                                description_info = None
                                for text in unique_texts:
                                    if 'spots' in text.lower() and len(text) < 30:
                                        description_info = text
                                        break
                                
                                class_info = {
                                    'date': current_date,
                                    'class_number': i + 1,
                                    'time': time_info,
                                    'duration': duration_info,
                                    'class_name': class_name_info,
                                    'instructor': instructor_info,
                                    'description': description_info
                                }
                                classes_data.append(class_info)
                                
                                print(f"  L·ªõp {i+1}: {time_info} - {class_name_info} - {instructor_info}")
                            
                            print(f"‚úÖ Ng√†y {current_date}: ƒê√£ scraper ƒë∆∞·ª£c {day_classes_count} l·ªõp h·ªçc")
                            # L∆∞u t·ªïng k·∫øt ng√†y
                            daily_summary.append(f"Ng√†y {current_date}: {day_classes_count} ti·∫øt h·ªçc")
                        else:
                            print(f"‚ö†Ô∏è Ng√†y {current_date}: Kh√¥ng c√≥ l·ªõp h·ªçc n√†o")
                            # L∆∞u t·ªïng k·∫øt ng√†y
                            daily_summary.append(f"Ng√†y {current_date}: 0 ti·∫øt h·ªçc")
                    
                    # Click v√†o button ti·∫øp theo (n·∫øu kh√¥ng ph·∫£i button cu·ªëi v√† ch∆∞a ƒë·∫°t gi·ªõi h·∫°n)
                    if day_index < total_days - 1 and total_processed_days < max_days:
                        print(f"üîÑ Click v√†o button ti·∫øp theo...")
                        next_button = buttons.nth(day_index + 1)
                        next_button.click()
                        print(f"‚úÖ ƒê√£ click v√†o button {day_index + 2}")
                        
                        # Ch·ªù 3 gi√¢y ƒë·ªÉ d·ªØ li·ªáu hi·ªán l√™n
                        time.sleep(3)
                        print("‚è≥ ƒê√£ ch·ªù 3 gi√¢y")
                    else:
                        print("üèÅ ƒê√£ x·ª≠ l√Ω xong t·∫•t c·∫£ c√°c ng√†y trong tu·∫ßn")
                
                # Ki·ªÉm tra ƒëi·ªÅu ki·ªán d·ª´ng sau khi x·ª≠ l√Ω tu·∫ßn
                if total_processed_days >= max_days:
                    print(f"\nüéØ ƒê√£ ƒë·∫°t gi·ªõi h·∫°n {max_days} ng√†y, d·ª´ng scraper")
                    break
                
                # Sau khi x·ª≠ l√Ω xong tu·∫ßn, t√¨m v√† click n√∫t Next Week (‚Ä∫)
                print(f"\n{'='*50}")
                print("üîÑ T√¨m n√∫t Next Week (‚Ä∫)...")
                
                # T√¨m n√∫t Next Week b·∫±ng nhi·ªÅu c√°ch kh√°c nhau
                next_week_button = None
                
                # C√°ch 1: T√¨m theo text content
                try:
                    next_week_button = page.locator('button:has-text("‚Ä∫")').first
                    if next_week_button.count() > 0:
                        print("‚úÖ T√¨m th·∫•y n√∫t Next Week b·∫±ng text ‚Ä∫")
                    else:
                        next_week_button = None
                except:
                    pass
                
                # C√°ch 2: T√¨m theo aria-label
                if next_week_button is None:
                    try:
                        next_week_button = page.locator('button[aria-label*="next"]').first
                        if next_week_button.count() > 0:
                            print("‚úÖ T√¨m th·∫•y n√∫t Next Week b·∫±ng aria-label")
                        else:
                            next_week_button = None
                    except:
                        pass
                
                # C√°ch 3: T√¨m theo class ho·∫∑c data attribute
                if next_week_button is None:
                    try:
                        next_week_button = page.locator('button[class*="next"], button[data-testid*="next"]').first
                        if next_week_button.count() > 0:
                            print("‚úÖ T√¨m th·∫•y n√∫t Next Week b·∫±ng class/data-testid")
                        else:
                            next_week_button = None
                    except:
                        pass
                
                # Click n√∫t Next Week n·∫øu t√¨m th·∫•y
                if next_week_button is not None:
                    print("üîÑ Click v√†o n√∫t Next Week...")
                    next_week_button.click()
                    print("‚úÖ ƒê√£ click v√†o n√∫t Next Week")
                    
                    # Ch·ªù 5 gi√¢y ƒë·ªÉ trang load tu·∫ßn m·ªõi
                    time.sleep(5)
                    print("‚è≥ ƒê√£ ch·ªù 5 gi√¢y ƒë·ªÉ load tu·∫ßn m·ªõi")
                    
                    # Ki·ªÉm tra xem c√≥ tu·∫ßn m·ªõi kh√¥ng
                    new_calendar_divs = page.locator('div[role="list"]')
                    if new_calendar_divs.count() > 0:
                        new_buttons = new_calendar_divs.first.locator('button')
                        new_total_days = new_buttons.count()
                        print(f"üìÖ Tu·∫ßn m·ªõi: T√¨m th·∫•y {new_total_days} ng√†y")
                        
                        # L·∫•y ng√†y ƒë·∫ßu ti√™n c·ªßa tu·∫ßn m·ªõi
                        if new_total_days > 0:
                            first_day = new_buttons.nth(0)
                            first_day_date = first_day.get_attribute("aria-label")
                            print(f"üéØ Ng√†y ƒë·∫ßu ti√™n tu·∫ßn m·ªõi: {first_day_date}")
                            
                            # Ti·∫øp t·ª•c v√≤ng l·∫∑p while ƒë·ªÉ x·ª≠ l√Ω tu·∫ßn m·ªõi
                            continue
                    else:
                        print("‚ùå Kh√¥ng t√¨m th·∫•y calendar m·ªõi")
                        break
                else:
                    print("‚ùå Kh√¥ng t√¨m th·∫•y n√∫t Next Week")
                    break
            
            browser.close()
            
            # L∆∞u d·ªØ li·ªáu v√†o file
            if classes_data:
                with open('classes_data.json', 'w', encoding='utf-8') as f:
                    json.dump(classes_data, f, ensure_ascii=False, indent=2)
                print(f"‚úÖ ƒê√£ l∆∞u {len(classes_data)} l·ªõp h·ªçc v√†o file")
            
            # C·∫≠p nh·∫≠t status
            scraping_status["total_classes"] = len(classes_data)
            scraping_status["daily_summary"] = daily_summary
            scraping_status["last_run"] = datetime.now().isoformat()
            scraping_status["progress"] = 100
            
            # In t·ªïng k·∫øt
            print(f"\n{'='*60}")
            print("üìã T·ªîNG K·∫æT CHI TI·∫æT")
            print(f"{'='*60}")
            for summary in daily_summary:
                print(summary)
            
            print(f"\n{'='*60}")
            print(f"üéØ T·ªîNG K·∫æT CU·ªêI C√ôNG")
            print(f"{'='*60}")
            print(f"Total {total_processed_days} ng√†y: {len(classes_data)} ti·∫øt h·ªçc")
            
    except Exception as e:
        print("‚úó L·ªói:", e)
        scraping_status["error"] = str(e)
    finally:
        scraping_status["is_running"] = False
        scraping_status["current_date"] = None

@app.get('/')
def home():
    return JSONResponse({
        "message": "Nosara Blue Classes Scraper API",
        "status": "running",
        "endpoints": {
            "/scrape": "POST - Trigger scraping",
            "/status": "GET - Get scraping status", 
            "/data": "GET - Get latest data"
        }
    })

@app.post('/scrape')
def trigger_scrape():
    """API endpoint ƒë·ªÉ n8n g·ªçi v√† trigger scraping"""
    global scraping_status
    
    if scraping_status["is_running"]:
        raise HTTPException(status_code=409, detail={
            "success": False,
            "message": "Scraping ƒëang ch·∫°y, vui l√≤ng ƒë·ª£i",
            "status": scraping_status
        })
    
    # Ch·∫°y scraper trong thread ri√™ng
    thread = threading.Thread(target=run_scraper)
    thread.daemon = True
    thread.start()
    
    return JSONResponse({
        "success": True,
        "message": "ƒê√£ b·∫Øt ƒë·∫ßu scraping",
        "status": scraping_status
    })

@app.get('/status')
def get_status():
    """API endpoint ƒë·ªÉ ki·ªÉm tra tr·∫°ng th√°i scraping"""
    return JSONResponse(scraping_status)

@app.get('/data')
def get_data():
    """API endpoint ƒë·ªÉ l·∫•y d·ªØ li·ªáu m·ªõi nh·∫•t"""
    try:
        if os.path.exists('classes_data.json'):
            with open('classes_data.json', 'r', encoding='utf-8') as f:
                data = json.load(f)
            return JSONResponse({
                "success": True,
                "total_classes": len(data),
                "data": data
            })
        else:
            raise HTTPException(status_code=404, detail={
                "success": False,
                "message": "Ch∆∞a c√≥ d·ªØ li·ªáu"
            })
    except Exception as e:
        raise HTTPException(status_code=500, detail={
            "success": False,
            "message": f"L·ªói ƒë·ªçc d·ªØ li·ªáu: {str(e)}"
        })

if __name__ == "__main__":
    import uvicorn
    port = int(os.environ.get('PORT', 8000))
    uvicorn.run(app, host='0.0.0.0', port=port)
